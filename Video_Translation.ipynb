{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinkokaki/CC2024translator/blob/colab/Video_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>\n",
        "    TRANSLATE OBJECTS IN VIDEO\n",
        "</center></h1>"
      ],
      "metadata": {
        "id": "u0kSAUQxbVGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "LAs0nMN4bzLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python tesserocr Pillow ffmpeg scikit-image numpy ipywidgets"
      ],
      "metadata": {
        "id": "-w9pZejJc8yG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d788cd2-56ca-451a-a02e-231ff3c8f016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting tesserocr\n",
            "  Downloading tesserocr-2.6.2-cp310-cp310-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.10)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=cad4bf56b2a09fef5fc582049e50a5e20447f38c6660b9bf604c35dc875cd2fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: tesserocr, ffmpeg, jedi\n",
            "Successfully installed ffmpeg-1.4 jedi-0.19.1 tesserocr-2.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, ffmpeg, re, shutil, glob, sys, csv\n",
        "import numpy as np, ipywidgets as widgets\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance\n",
        "from google.cloud import translate_v2 as translate\n",
        "from tesserocr import PyTessBaseAPI, PSM, OEM\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage.morphology import disk\n",
        "from skimage.filters import rank\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "7DKAl1fxbzhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Convert video to images\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "qzS0NHbNbsN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYBod1OHbADz"
      },
      "outputs": [],
      "source": [
        "def split_video_to_png(video_path):\n",
        "    output_folder = \"split_images\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Read the first frame\n",
        "    success, frame = video_capture.read()\n",
        "    count = 0\n",
        "\n",
        "    # Loop through the video frames\n",
        "    while success:\n",
        "        # Write the frame as a PNG image\n",
        "        cv2.imwrite(f\"{output_folder}/frame_{count:04d}.png\", frame)\n",
        "\n",
        "        # Read the next frame\n",
        "        success, frame = video_capture.read()\n",
        "        count += 1\n",
        "\n",
        "    # Release the video capture object\n",
        "    video_capture.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    OCR images to get text and positional data\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "roJPwUqEb4sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "please only run this once if the folder doesn't already exist"
      ],
      "metadata": {
        "id": "TGyQxhMos_cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s -L https://github.com/tesseract-ocr/tessdata/archive/refs/tags/4.1.0.tar.gz | tar xvz"
      ],
      "metadata": {
        "id": "pqFJc94FpQD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b7e6d6-0b48-48f2-b8ae-172e7e187a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tessdata-4.1.0/\n",
            "tessdata-4.1.0/.gitmodules\n",
            "tessdata-4.1.0/LICENSE\n",
            "tessdata-4.1.0/README.md\n",
            "tessdata-4.1.0/afr.traineddata\n",
            "tessdata-4.1.0/amh.traineddata\n",
            "tessdata-4.1.0/ara.traineddata\n",
            "tessdata-4.1.0/asm.traineddata\n",
            "tessdata-4.1.0/aze.traineddata\n",
            "tessdata-4.1.0/aze_cyrl.traineddata\n",
            "tessdata-4.1.0/bel.traineddata\n",
            "tessdata-4.1.0/ben.traineddata\n",
            "tessdata-4.1.0/bod.traineddata\n",
            "tessdata-4.1.0/bos.traineddata\n",
            "tessdata-4.1.0/bre.traineddata\n",
            "tessdata-4.1.0/bul.traineddata\n",
            "tessdata-4.1.0/cat.traineddata\n",
            "tessdata-4.1.0/ceb.traineddata\n",
            "tessdata-4.1.0/ces.traineddata\n",
            "tessdata-4.1.0/chi_sim.traineddata\n",
            "tessdata-4.1.0/chi_sim_vert.traineddata\n",
            "tessdata-4.1.0/chi_tra.traineddata\n",
            "tessdata-4.1.0/chi_tra_vert.traineddata\n",
            "tessdata-4.1.0/chr.traineddata\n",
            "tessdata-4.1.0/configs\n",
            "tessdata-4.1.0/cos.traineddata\n",
            "tessdata-4.1.0/cym.traineddata\n",
            "tessdata-4.1.0/dan.traineddata\n",
            "tessdata-4.1.0/dan_frak.traineddata\n",
            "tessdata-4.1.0/deu.traineddata\n",
            "tessdata-4.1.0/deu_frak.traineddata\n",
            "tessdata-4.1.0/div.traineddata\n",
            "tessdata-4.1.0/dzo.traineddata\n",
            "tessdata-4.1.0/ell.traineddata\n",
            "tessdata-4.1.0/eng.traineddata\n",
            "tessdata-4.1.0/enm.traineddata\n",
            "tessdata-4.1.0/epo.traineddata\n",
            "tessdata-4.1.0/equ.traineddata\n",
            "tessdata-4.1.0/est.traineddata\n",
            "tessdata-4.1.0/eus.traineddata\n",
            "tessdata-4.1.0/fao.traineddata\n",
            "tessdata-4.1.0/fas.traineddata\n",
            "tessdata-4.1.0/fil.traineddata\n",
            "tessdata-4.1.0/fin.traineddata\n",
            "tessdata-4.1.0/fra.traineddata\n",
            "tessdata-4.1.0/frk.traineddata\n",
            "tessdata-4.1.0/frm.traineddata\n",
            "tessdata-4.1.0/fry.traineddata\n",
            "tessdata-4.1.0/gla.traineddata\n",
            "tessdata-4.1.0/gle.traineddata\n",
            "tessdata-4.1.0/glg.traineddata\n",
            "tessdata-4.1.0/grc.traineddata\n",
            "tessdata-4.1.0/guj.traineddata\n",
            "tessdata-4.1.0/hat.traineddata\n",
            "tessdata-4.1.0/heb.traineddata\n",
            "tessdata-4.1.0/hin.traineddata\n",
            "tessdata-4.1.0/hrv.traineddata\n",
            "tessdata-4.1.0/hun.traineddata\n",
            "tessdata-4.1.0/hye.traineddata\n",
            "tessdata-4.1.0/iku.traineddata\n",
            "tessdata-4.1.0/ind.traineddata\n",
            "tessdata-4.1.0/isl.traineddata\n",
            "tessdata-4.1.0/ita.traineddata\n",
            "tessdata-4.1.0/ita_old.traineddata\n",
            "tessdata-4.1.0/jav.traineddata\n",
            "tessdata-4.1.0/jpn.traineddata\n",
            "tessdata-4.1.0/jpn_vert.traineddata\n",
            "tessdata-4.1.0/kan.traineddata\n",
            "tessdata-4.1.0/kat.traineddata\n",
            "tessdata-4.1.0/kat_old.traineddata\n",
            "tessdata-4.1.0/kaz.traineddata\n",
            "tessdata-4.1.0/khm.traineddata\n",
            "tessdata-4.1.0/kir.traineddata\n",
            "tessdata-4.1.0/kmr.traineddata\n",
            "tessdata-4.1.0/kor.traineddata\n",
            "tessdata-4.1.0/kor_vert.traineddata\n",
            "tessdata-4.1.0/lao.traineddata\n",
            "tessdata-4.1.0/lat.traineddata\n",
            "tessdata-4.1.0/lav.traineddata\n",
            "tessdata-4.1.0/lit.traineddata\n",
            "tessdata-4.1.0/ltz.traineddata\n",
            "tessdata-4.1.0/mal.traineddata\n",
            "tessdata-4.1.0/mar.traineddata\n",
            "tessdata-4.1.0/mkd.traineddata\n",
            "tessdata-4.1.0/mlt.traineddata\n",
            "tessdata-4.1.0/mon.traineddata\n",
            "tessdata-4.1.0/mri.traineddata\n",
            "tessdata-4.1.0/msa.traineddata\n",
            "tessdata-4.1.0/mya.traineddata\n",
            "tessdata-4.1.0/nep.traineddata\n",
            "tessdata-4.1.0/nld.traineddata\n",
            "tessdata-4.1.0/nor.traineddata\n",
            "tessdata-4.1.0/oci.traineddata\n",
            "tessdata-4.1.0/ori.traineddata\n",
            "tessdata-4.1.0/osd.traineddata\n",
            "tessdata-4.1.0/pan.traineddata\n",
            "tessdata-4.1.0/pdf.ttf\n",
            "tessdata-4.1.0/pol.traineddata\n",
            "tessdata-4.1.0/por.traineddata\n",
            "tessdata-4.1.0/pus.traineddata\n",
            "tessdata-4.1.0/que.traineddata\n",
            "tessdata-4.1.0/ron.traineddata\n",
            "tessdata-4.1.0/rus.traineddata\n",
            "tessdata-4.1.0/san.traineddata\n",
            "tessdata-4.1.0/script/\n",
            "tessdata-4.1.0/script/Arabic.traineddata\n",
            "tessdata-4.1.0/script/Armenian.traineddata\n",
            "tessdata-4.1.0/script/Bengali.traineddata\n",
            "tessdata-4.1.0/script/Canadian_Aboriginal.traineddata\n",
            "tessdata-4.1.0/script/Cherokee.traineddata\n",
            "tessdata-4.1.0/script/Cyrillic.traineddata\n",
            "tessdata-4.1.0/script/Devanagari.traineddata\n",
            "tessdata-4.1.0/script/Ethiopic.traineddata\n",
            "tessdata-4.1.0/script/Fraktur.traineddata\n",
            "tessdata-4.1.0/script/Georgian.traineddata\n",
            "tessdata-4.1.0/script/Greek.traineddata\n",
            "tessdata-4.1.0/script/Gujarati.traineddata\n",
            "tessdata-4.1.0/script/Gurmukhi.traineddata\n",
            "tessdata-4.1.0/script/HanS.traineddata\n",
            "tessdata-4.1.0/script/HanS_vert.traineddata\n",
            "tessdata-4.1.0/script/HanT.traineddata\n",
            "tessdata-4.1.0/script/HanT_vert.traineddata\n",
            "tessdata-4.1.0/script/Hangul.traineddata\n",
            "tessdata-4.1.0/script/Hangul_vert.traineddata\n",
            "tessdata-4.1.0/script/Hebrew.traineddata\n",
            "tessdata-4.1.0/script/Japanese.traineddata\n",
            "tessdata-4.1.0/script/Japanese_vert.traineddata\n",
            "tessdata-4.1.0/script/Kannada.traineddata\n",
            "tessdata-4.1.0/script/Khmer.traineddata\n",
            "tessdata-4.1.0/script/Lao.traineddata\n",
            "tessdata-4.1.0/script/Latin.traineddata\n",
            "tessdata-4.1.0/script/Malayalam.traineddata\n",
            "tessdata-4.1.0/script/Myanmar.traineddata\n",
            "tessdata-4.1.0/script/Oriya.traineddata\n",
            "tessdata-4.1.0/script/Sinhala.traineddata\n",
            "tessdata-4.1.0/script/Syriac.traineddata\n",
            "tessdata-4.1.0/script/Tamil.traineddata\n",
            "tessdata-4.1.0/script/Telugu.traineddata\n",
            "tessdata-4.1.0/script/Thaana.traineddata\n",
            "tessdata-4.1.0/script/Thai.traineddata\n",
            "tessdata-4.1.0/script/Tibetan.traineddata\n",
            "tessdata-4.1.0/script/Vietnamese.traineddata\n",
            "tessdata-4.1.0/sin.traineddata\n",
            "tessdata-4.1.0/slk.traineddata\n",
            "tessdata-4.1.0/slk_frak.traineddata\n",
            "tessdata-4.1.0/slv.traineddata\n",
            "tessdata-4.1.0/snd.traineddata\n",
            "tessdata-4.1.0/spa.traineddata\n",
            "tessdata-4.1.0/spa_old.traineddata\n",
            "tessdata-4.1.0/sqi.traineddata\n",
            "tessdata-4.1.0/srp.traineddata\n",
            "tessdata-4.1.0/srp_latn.traineddata\n",
            "tessdata-4.1.0/sun.traineddata\n",
            "tessdata-4.1.0/swa.traineddata\n",
            "tessdata-4.1.0/swe.traineddata\n",
            "tessdata-4.1.0/syr.traineddata\n",
            "tessdata-4.1.0/tam.traineddata\n",
            "tessdata-4.1.0/tat.traineddata\n",
            "tessdata-4.1.0/tel.traineddata\n",
            "tessdata-4.1.0/tessconfigs/\n",
            "tessdata-4.1.0/tgk.traineddata\n",
            "tessdata-4.1.0/tgl.traineddata\n",
            "tessdata-4.1.0/tha.traineddata\n",
            "tessdata-4.1.0/tir.traineddata\n",
            "tessdata-4.1.0/ton.traineddata\n",
            "tessdata-4.1.0/tur.traineddata\n",
            "tessdata-4.1.0/uig.traineddata\n",
            "tessdata-4.1.0/ukr.traineddata\n",
            "tessdata-4.1.0/urd.traineddata\n",
            "tessdata-4.1.0/uzb.traineddata\n",
            "tessdata-4.1.0/uzb_cyrl.traineddata\n",
            "tessdata-4.1.0/vie.traineddata\n",
            "tessdata-4.1.0/yid.traineddata\n",
            "tessdata-4.1.0/yor.traineddata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.convert('L')\n",
        "    img = img_as_ubyte(image)\n",
        "    img_tmp = rank.equalize(np.array(img), disk(30))\n",
        "    img_tmp = cv2.threshold(img_tmp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    img_eq = Image.fromarray(img_tmp)\n",
        "    enhancer = ImageEnhance.Contrast(img_eq)\n",
        "    img_eq = enhancer.enhance(2)\n",
        "    img_eq.save(\"temp.png\")\n",
        "    return img_eq"
      ],
      "metadata": {
        "id": "rYZLuUFSOH9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api = PyTessBaseAPI(path=\"tessdata-4.1.0\",lang=\"jpn+eng\",psm=PSM.AUTO_OSD,oem=OEM.LSTM_ONLY)\n",
        "\n",
        "def init(image_name, is_video):\n",
        "    if is_video:\n",
        "      image = preprocess_image(\"split_images/\" + image_name)\n",
        "    else:\n",
        "      image = preprocess_image(image_name)\n",
        "    api.SetImage(image)\n",
        "    api.Recognize()\n",
        "\n",
        "def get_orientation():\n",
        "    it = api.AnalyseLayout()\n",
        "    orientation, direction, order, deskew_angle = it.Orientation()\n",
        "    return format(orientation), format(deskew_angle)\n",
        "\n",
        "def write_TSV():\n",
        "    with open(\"results.tsv\", \"w\") as result:\n",
        "        result.write(api.GetTSVText(0))\n",
        "        result.close()\n",
        "\n",
        "    #with open(\"results.tsv\", \"r\") as result:\n",
        "    #    print(result.read())\n",
        "\n",
        "def get_regions():\n",
        "    regions = []\n",
        "    with open(\"results.tsv\", \"r\") as tsv:\n",
        "        f = csv.reader(tsv, delimiter='\\t', quotechar='\"')\n",
        "        i = 0\n",
        "        str = \"\"\n",
        "        left = []\n",
        "        top = []\n",
        "        right = []\n",
        "        bottom = []\n",
        "        for row in f:\n",
        "            if float(row[2]) == i:\n",
        "                if float(row[10]) == 0 or float(row[10]) > 80:\n",
        "                    str = \" \".join((str, row[11]))\n",
        "                    left.append(float(row[6]))\n",
        "                    top.append(float(row[7]))\n",
        "                    right.append(float(row[6]) + float(row[8]))\n",
        "                    bottom.append(float(row[7]) + float(row[9]))\n",
        "            else:\n",
        "                if (not str.isspace() and str.strip()):\n",
        "                    regions.append((str, min(left, default=-1), min(top, default=-1), max(right, default=-1), max(bottom, default=-1)))\n",
        "                left = []\n",
        "                top = []\n",
        "                right = []\n",
        "                bottom = []\n",
        "                str = \"\"\n",
        "                i = i + 1\n",
        "        if (not str.isspace() and str.strip()):\n",
        "            regions.append((str, min(left, default=-1), min(top, default=-1), max(right, default=-1), max(bottom, default=-1)))\n",
        "    return regions\n",
        "\n",
        "def end():\n",
        "    api.End()"
      ],
      "metadata": {
        "id": "adwLtZtVeMvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Translate text to English\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "c29NsxNdcAyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/buoyant-song-414621-671aac12546a.json'\n",
        "\n",
        "# Function to translate text using Google Cloud Translation API\n",
        "def translate_text(text):\n",
        "    client = translate.Client()\n",
        "    return client.translate(text, 'en')['translatedText']"
      ],
      "metadata": {
        "id": "bkI6dN_ylM1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_regions(regions):\n",
        "    translated_region = []\n",
        "    for phrase in regions:\n",
        "        #remove all non standard characters\n",
        "        translated_text = translate_text(phrase[0].strip())\n",
        "\n",
        "        if any(char.isalpha() for char in translated_text):\n",
        "          translated_region.append((translated_text,) + phrase[1:])\n",
        "    return translated_region"
      ],
      "metadata": {
        "id": "_X1XeAwwchXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Replace text in images with translated text\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "C1amkzM1cIRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the maximum font size that still fits within the box\n",
        "def find_max_font_size(text, box_height, box_width):\n",
        "    low = 1\n",
        "    high = 1000\n",
        "    max_font_size = 1\n",
        "\n",
        "    while low <= high:\n",
        "        mid = (low + high) // 2\n",
        "        font = ImageFont.truetype(\"arial.ttf\", mid)\n",
        "        bbox = font.getbbox(text)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "\n",
        "        if text_width <= box_width and text_height <= box_height:\n",
        "            max_font_size = mid\n",
        "            low = mid + 1\n",
        "        else:\n",
        "            high = mid - 1\n",
        "\n",
        "    return max_font_size"
      ],
      "metadata": {
        "id": "vVEPo7sMeVrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the text to the images\n",
        "def add_text_to_image(image_name, text, x, y, x2, y2, is_video):\n",
        "    output_folder = \"translated_images\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    width = x2 - x\n",
        "    height = y2 - y\n",
        "\n",
        "    if is_video: # is video we save to an additional folder\n",
        "      # Check if the translated image exists\n",
        "      translated_image_name = output_folder + \"/\" + image_name.rsplit('.', 1)[0] + \"_translated.\" + image_name.rsplit('.', 1)[1]\n",
        "      print(image_name + \" - \", end=\"\")\n",
        "\n",
        "      if os.path.exists(translated_image_name):\n",
        "        img_to_open = translated_image_name\n",
        "        print(\"Old image\")\n",
        "      else:\n",
        "        img_to_open = \"split_images/\" + image_name\n",
        "        print(\"New image\")\n",
        "\n",
        "    else: # image so save to same dir\n",
        "      translated_image_name = image_name.rsplit('.', 1)[0] + \"_translated.\" + image_name.rsplit('.', 1)[1]\n",
        "      print(image_name + \" - \", end=\"\")\n",
        "\n",
        "      # Check if the translated file exists\n",
        "      if os.path.exists(translated_image_name):\n",
        "          img_to_open = translated_image_name\n",
        "          print(\"Old image\")\n",
        "      else:\n",
        "          img_to_open = image_name\n",
        "          print(\"New image\")\n",
        "\n",
        "    # Open the image\n",
        "    with Image.open(img_to_open) as img:\n",
        "        # Create a new image in memory\n",
        "        new_img = img.copy()\n",
        "\n",
        "        # Calculate the average color of the specified box\n",
        "        box = (x, y, x + width, y + height)\n",
        "        box_area = new_img.crop(box)\n",
        "        avg_color = map(lambda x: int(sum(x) / len(x)), zip(*box_area.getdata()))\n",
        "\n",
        "        # Create a draw object to add text to the image\n",
        "        draw = ImageDraw.Draw(new_img)\n",
        "\n",
        "        # Load a font\n",
        "        font_size = find_max_font_size(text, height, width) # Adjust font size based on the box size and text length\n",
        "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
        "\n",
        "        # Draw a rectangle with the average color\n",
        "        #avg_color = \"#ffffff\"\n",
        "        draw.rectangle(box, fill=avg_color)\n",
        "\n",
        "        # Add text on top of the rectangle\n",
        "        text_bbox = draw.textbbox((x, y), text, font=font)\n",
        "        text_width = text_bbox[2] - text_bbox[0]\n",
        "        text_height = text_bbox[3] - text_bbox[1]\n",
        "        text_x = x + (width - text_width) // 2  # Center the text within the box\n",
        "        text_y = y + (height - text_height) // 2\n",
        "        draw.text((text_x, text_y), text, fill=\"black\", font=font)\n",
        "\n",
        "        # Save the new image with \"_translated\" added to the original name\n",
        "        new_img.save(translated_image_name)"
      ],
      "metadata": {
        "id": "_6fRB6LIcIpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Convert images back to video (without sound)\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "ADwMsK6ncOTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sync_images():\n",
        "    split_images_folder = \"split_images\"\n",
        "    translated_images_folder = \"translated_images\"\n",
        "\n",
        "    # Ensure the translated_images_folder exists\n",
        "    os.makedirs(translated_images_folder, exist_ok=True)\n",
        "\n",
        "    # Count the number of images in split_images_folder\n",
        "    num_images = len([file for file in os.listdir(split_images_folder) if file.endswith('.png')])\n",
        "\n",
        "    # Iterate through the images in split_images_folder\n",
        "    for file in os.listdir(split_images_folder):\n",
        "        if file.endswith('.png'):\n",
        "            frame_number = file.split('_')[1].split('.')[0]  # Extract the frame number\n",
        "            translated_file = f\"frame_{frame_number}_translated.png\"\n",
        "            translated_path = os.path.join(translated_images_folder, translated_file)\n",
        "\n",
        "            # Check if the translated file exists and if the frame number is lower than num_images\n",
        "            if not os.path.exists(translated_path) and int(frame_number) < num_images:\n",
        "                source_path = os.path.join(split_images_folder, file)\n",
        "                shutil.copy(source_path, translated_path)\n",
        "                print(f\"Copied {file} to {translated_path}\")"
      ],
      "metadata": {
        "id": "gsbv136aJvSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def images_to_video(video_name):\n",
        "    imgFolder = \"translated_images\"\n",
        "    vidName = \"video_output.mp4\"\n",
        "\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    cap.release()\n",
        "\n",
        "    images = glob.glob(os.path.join(imgFolder, \"*.png\"))\n",
        "    images.sort()\n",
        "\n",
        "    width, height = Image.open(images[0]).size\n",
        "    size = (width, height)\n",
        "    codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    if len(sys.argv) < 2:\n",
        "        video = cv2.VideoWriter(vidName, codec, fps, (width, height))\n",
        "    else:\n",
        "        video = cv2.VideoWriter(vidName, codec, fps, size)\n",
        "\n",
        "    for img in images:\n",
        "        frame = cv2.imread(img)\n",
        "        video.write(frame)\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "G3AI1BUefSTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Process Image\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "zI9wzbOcVFV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_name):\n",
        "    # process images with ocr\n",
        "    init(image_name, False)\n",
        "    write_TSV()\n",
        "    regions = get_regions()\n",
        "\n",
        "    # translate text\n",
        "    translated_regions = translate_regions(regions)\n",
        "\n",
        "    # overlay new text on images\n",
        "    for phrase in translated_regions:\n",
        "        print(\"Image: \" + image_name + \" text: \" + phrase[0] + \" x: \" + str(phrase[1]) + \" y: \" + str(phrase[2]) + \" height: \" + str(phrase[3]) + \" width: \" + str(phrase[4]))\n",
        "        add_text_to_image(image_name, phrase[0], phrase[1], phrase[2], phrase[3], phrase[4], False)\n",
        "    print(\"Image Processed Successfully!\")"
      ],
      "metadata": {
        "id": "h0gQESHNVDmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>\n",
        "    Process Video\n",
        "</center></h2>"
      ],
      "metadata": {
        "id": "xxODnpvRVEKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video(video_name):\n",
        "    split_images_folder = 'split_images'\n",
        "\n",
        "    # process video to images\n",
        "    split_video_to_png(video_name)\n",
        "\n",
        "    # process images with ocr\n",
        "    for frame in os.listdir(split_images_folder):\n",
        "      file_name = os.path.basename(frame)\n",
        "      init(frame, True)\n",
        "      write_TSV()\n",
        "      regions = get_regions()\n",
        "\n",
        "      # translate text\n",
        "      translated_regions = translate_regions(regions)\n",
        "\n",
        "      # overlay new text on images\n",
        "      for phrase in translated_regions:\n",
        "        print(\"Frame: \" + frame + \" text: \" + phrase[0] + \" x: \" + str(phrase[1]) + \" y: \" + str(phrase[2]) + \" height: \" + str(phrase[3]) + \" width: \" + str(phrase[4]))\n",
        "        add_text_to_image(frame, phrase[0], phrase[1], phrase[2], phrase[3], phrase[4], True)\n",
        "\n",
        "    # save as video (without sound)\n",
        "    sync_images()\n",
        "    images_to_video(video_name)\n",
        "\n",
        "    print(\"Video Processed Successfully!\")"
      ],
      "metadata": {
        "id": "h5vk5ilfVE_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>\n",
        "    Main Function\n",
        "</center></h1>"
      ],
      "metadata": {
        "id": "Acr2J6DsewuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    process_video(\"input_video2.mp4\")\n",
        "    # Define the upload widget\n",
        "    upload = widgets.FileUpload(\n",
        "        accept='.mp4, .png',  # Accepted file types\n",
        "        multiple=False  # Only allow one file to be uploaded\n",
        "    )\n",
        "\n",
        "    # Define the submit button\n",
        "    submit_button = widgets.Button(\n",
        "        description='Submit',\n",
        "        disabled=True,  # Initially disabled\n",
        "        button_style='',  # Initially gray\n",
        "        layout={'visibility': 'visible'}  # Initially visible\n",
        "    )\n",
        "\n",
        "    # Define the output widget to display messages\n",
        "    output = widgets.Output()\n",
        "    file_name = \"\"\n",
        "\n",
        "    def on_upload_change(change):\n",
        "        if upload.value:\n",
        "            submit_button.disabled = False  # Enable the button\n",
        "            submit_button.button_style = 'success'  # Change to green\n",
        "        else:\n",
        "            submit_button.disabled = True  # Disable the button\n",
        "            submit_button.button_style = ''  # Change to gray\n",
        "\n",
        "    def on_submit_button_clicked(b):\n",
        "        with output:\n",
        "            if upload.value:\n",
        "                # Retrieve the uploaded file\n",
        "                uploaded_file = next(iter(upload.value.values()))\n",
        "\n",
        "                # Save the file\n",
        "                file_name = uploaded_file['metadata']['name']\n",
        "                content = uploaded_file['content']\n",
        "                with open(file_name, 'wb') as f:\n",
        "                    f.write(content)\n",
        "\n",
        "                # Update the message\n",
        "                print(f\"File {file_name} has been uploaded and saved.\")\n",
        "\n",
        "                # Hide the widgets\n",
        "                upload.layout.visibility = 'hidden'\n",
        "                submit_button.layout.visibility = 'hidden'\n",
        "\n",
        "                if file_name.endswith('.mp4'): # video\n",
        "                    process_video(file_name)\n",
        "                elif file_name.endswith('.png'): # image\n",
        "                    process_image(file_name)\n",
        "                else: # invalid file type\n",
        "                    print(f\"Error: File '{file_name}' is not an MP4 or PNG file.\")\n",
        "\n",
        "    # Attach the event handlers\n",
        "    upload.observe(on_upload_change, names='value')\n",
        "    submit_button.on_click(on_submit_button_clicked)\n",
        "\n",
        "    # Display the widgets\n",
        "    display(upload, submit_button, output)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "LBPvqKZoewPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661925d0-04c4-448a-a19e-e22704b12aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame: frame_0112.png text: - Save - a x: 38.0 y: 104.0 height: 80.0 width: 309.0\n",
            "frame_0112.png - Old image\n",
            "Frame: frame_0112.png text: moon x: 0.0 y: 349.0 height: 43.0 width: 367.0\n",
            "frame_0112.png - Old image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete everything in \"transplated_images\" using rm rf\n",
        "\n",
        "#!rm -rf translated_images\n",
        "#!rm -rf split_images/"
      ],
      "metadata": {
        "id": "N0xZ8hRCieEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}